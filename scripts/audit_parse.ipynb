{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b95fed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 527 HTML files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing HTML files:  19%|███▍              | 102/527 [00:05<00:23, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved intermediate results for 100 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing HTML files:  39%|██████▉           | 203/527 [00:10<00:17, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved intermediate results for 200 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing HTML files:  57%|██████████▎       | 303/527 [00:15<00:11, 18.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved intermediate results for 300 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing HTML files:  76%|█████████████▋    | 402/527 [00:20<00:07, 17.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved intermediate results for 400 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing HTML files:  95%|█████████████████▏| 503/527 [00:25<00:01, 19.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved intermediate results for 500 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing HTML files: 100%|██████████████████| 527/527 [00:26<00:00, 19.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved final results to final_audit_results.csv\n",
      "Total records processed: 527\n",
      "\n",
      "DataFrame Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 527 entries, 0 to 526\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   state                        524 non-null    object\n",
      " 1   district                     524 non-null    object\n",
      " 2   block                        524 non-null    object\n",
      " 3   panchayat                    524 non-null    object\n",
      " 4   sa_start_date                524 non-null    object\n",
      " 5   sa_end_date                  524 non-null    object\n",
      " 6   gram_sabha_date              524 non-null    object\n",
      " 7   public_hearing_date          524 non-null    object\n",
      " 8   sa_period_from               524 non-null    object\n",
      " 9   sa_period_to                 524 non-null    object\n",
      " 10  wage_exp                     524 non-null    object\n",
      " 11  material_exp                 524 non-null    object\n",
      " 12  total_exp                    524 non-null    object\n",
      " 13  wage_given                   524 non-null    object\n",
      " 14  material_given               524 non-null    object\n",
      " 15  total_given                  524 non-null    object\n",
      " 16  total_works                  524 non-null    object\n",
      " 17  total_households             524 non-null    object\n",
      " 18  works_verified               524 non-null    object\n",
      " 19  households_verified          524 non-null    object\n",
      " 20  gram_sabha_participants      524 non-null    object\n",
      " 21  printing_expense             523 non-null    object\n",
      " 22  videography_expense          523 non-null    object\n",
      " 23  tea_expense                  523 non-null    object\n",
      " 24  vrp_training_expense         523 non-null    object\n",
      " 25  vrp_travel_expense           523 non-null    object\n",
      " 26  photocopying_expense         523 non-null    object\n",
      " 27  other_expense                523 non-null    object\n",
      " 28  vrp_honorarium_expense       523 non-null    object\n",
      " 29  stationary_expense           523 non-null    object\n",
      " 30  publicity_expense            523 non-null    object\n",
      " 31  mic_expense                  523 non-null    object\n",
      " 32  photography_expense          523 non-null    object\n",
      " 33  shamiana_expense             523 non-null    object\n",
      " 34  total_expense                523 non-null    object\n",
      " 35  job_cards_with_people        524 non-null    object\n",
      " 36  job_cards_updated            524 non-null    object\n",
      " 37  job_cards_renewed            524 non-null    object\n",
      " 38  demand_registration_process  524 non-null    object\n",
      " 39  unmet_demand                 524 non-null    object\n",
      " 40  payment_agency_problems      524 non-null    object\n",
      " 41  source_file                  527 non-null    object\n",
      "dtypes: object(42)\n",
      "memory usage: 173.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_info_from_html(file_path):\n",
    "    \"\"\"Extract all relevant information from a single HTML file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    \n",
    "    # Initialize data dictionary\n",
    "    data = {}\n",
    "    \n",
    "    # Basic Information\n",
    "    basic_fields = {\n",
    "        'state': 'ctl00_ContentPlaceHolder1_lblstate',\n",
    "        'district': 'ctl00_ContentPlaceHolder1_lbldistrict',\n",
    "        'block': 'ctl00_ContentPlaceHolder1_lblblock',\n",
    "        'panchayat': 'ctl00_ContentPlaceHolder1_lblpanchayat',\n",
    "        'sa_start_date': 'ctl00_ContentPlaceHolder1_lblSA_start_dt',\n",
    "        'sa_end_date': 'ctl00_ContentPlaceHolder1_lblSA_end_dt',\n",
    "        'gram_sabha_date': 'ctl00_ContentPlaceHolder1_lblGramSabha_dt',\n",
    "        'public_hearing_date': 'ctl00_ContentPlaceHolder1_lblPublic_Hearing_dt'\n",
    "    }\n",
    "    \n",
    "    # Extract basic fields\n",
    "    for key, id_value in basic_fields.items():\n",
    "        element = soup.find('span', id=id_value)\n",
    "        data[key] = element.text.strip() if element else None\n",
    "    \n",
    "    # Financial Information\n",
    "    financial_fields = {\n",
    "        'sa_period_from': 'ctl00_ContentPlaceHolder1_lblSA_Period_From_Date',\n",
    "        'sa_period_to': 'ctl00_ContentPlaceHolder1_lblSA_Period_To_Date',\n",
    "        'wage_exp': 'ctl00_ContentPlaceHolder1_lblWage_exp',\n",
    "        'material_exp': 'ctl00_ContentPlaceHolder1_lblmat_exp',\n",
    "        'total_exp': 'ctl00_ContentPlaceHolder1_lbltotal_expen',\n",
    "        'wage_given': 'ctl00_ContentPlaceHolder1_lblwage_given',\n",
    "        'material_given': 'ctl00_ContentPlaceHolder1_lblmat_given',\n",
    "        'total_given': 'ctl00_ContentPlaceHolder1_lbltotal_record_given'\n",
    "    }\n",
    "    \n",
    "    # Extract financial fields\n",
    "    for key, id_value in financial_fields.items():\n",
    "        element = soup.find('span', id=id_value)\n",
    "        data[key] = element.text.strip() if element else None\n",
    "    \n",
    "    # Work Information\n",
    "    work_fields = {\n",
    "        'total_works': 'ctl00_ContentPlaceHolder1_lbltot_work',\n",
    "        'total_households': 'ctl00_ContentPlaceHolder1_lbltot_hh',\n",
    "        'works_verified': 'ctl00_ContentPlaceHolder1_lbltot_work_verified',\n",
    "        'households_verified': 'ctl00_ContentPlaceHolder1_lbltot_hh_verified',\n",
    "        'gram_sabha_participants': 'ctl00_ContentPlaceHolder1_lblno_of_ppl_participated_gs'\n",
    "    }\n",
    "    \n",
    "    # Extract work fields\n",
    "    for key, id_value in work_fields.items():\n",
    "        element = soup.find('span', id=id_value)\n",
    "        data[key] = element.text.strip() if element else None\n",
    "    \n",
    "    # Extract expenses\n",
    "    expense_fields = {\n",
    "        'printing_expense': 'ctl00_ContentPlaceHolder1_lblprinting_expense',\n",
    "        'videography_expense': 'ctl00_ContentPlaceHolder1_lblvideography_expense',\n",
    "        'tea_expense': 'ctl00_ContentPlaceHolder1_lbltea_expense',\n",
    "        'vrp_training_expense': 'ctl00_ContentPlaceHolder1_lblvrp_training_expense',\n",
    "        'vrp_travel_expense': 'ctl00_ContentPlaceHolder1_lblvrp_travel_expense',\n",
    "        'photocopying_expense': 'ctl00_ContentPlaceHolder1_lblphotocopying_expense',\n",
    "        'other_expense': 'ctl00_ContentPlaceHolder1_lblother_expense',\n",
    "        'vrp_honorarium_expense': 'ctl00_ContentPlaceHolder1_lblvrp_honorium_expense',\n",
    "        'stationary_expense': 'ctl00_ContentPlaceHolder1_lblstationary_expense',\n",
    "        'publicity_expense': 'ctl00_ContentPlaceHolder1_lblpublicity_expense',\n",
    "        'mic_expense': 'ctl00_ContentPlaceHolder1_lblmic_expense',\n",
    "        'photography_expense': 'ctl00_ContentPlaceHolder1_lblphotography_expense',\n",
    "        'shamiana_expense': 'ctl00_ContentPlaceHolder1_lblshamiana_expense',\n",
    "        'total_expense': 'ctl00_ContentPlaceHolder1_lbltotal_expense'\n",
    "    }\n",
    "    \n",
    "    # Extract expense fields\n",
    "    for key, id_value in expense_fields.items():\n",
    "        element = soup.find('span', id=id_value)\n",
    "        data[key] = element.text.strip() if element else None\n",
    "    \n",
    "    # Extract checklist responses\n",
    "    checklist_fields = {\n",
    "        'job_cards_with_people': 'ctl00_ContentPlaceHolder1_Label1',\n",
    "        'job_cards_updated': 'ctl00_ContentPlaceHolder1_Label3',\n",
    "        'job_cards_renewed': 'ctl00_ContentPlaceHolder1_Label4',\n",
    "        'demand_registration_process': 'ctl00_ContentPlaceHolder1_Label2',\n",
    "        'unmet_demand': 'ctl00_ContentPlaceHolder1_Label29',\n",
    "        'payment_agency_problems': 'ctl00_ContentPlaceHolder1_Label30'\n",
    "    }\n",
    "    \n",
    "    # Extract checklist fields\n",
    "    for key, id_value in checklist_fields.items():\n",
    "        element = soup.find('span', id=id_value)\n",
    "        data[key] = element.text.strip() if element else None\n",
    "    \n",
    "    # Add source file\n",
    "    data['source_file'] = file_path.name\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_html_folder(folder_path):\n",
    "    \"\"\"Process all HTML files in the given folder.\"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    html_files = list(folder.glob('*.html'))\n",
    "    \n",
    "    print(f\"Found {len(html_files)} HTML files to process\")\n",
    "    results = []\n",
    "    \n",
    "    for file_path in tqdm(html_files, desc=\"Processing HTML files\"):\n",
    "        try:\n",
    "            data = extract_info_from_html(file_path)\n",
    "            results.append(data)\n",
    "            \n",
    "            # Save intermediate results every 100 files\n",
    "            if len(results) % 100 == 0:\n",
    "                pd.DataFrame(results).to_csv(f'intermediate_results_{len(results)}.csv', index=False)\n",
    "                print(f\"\\nSaved intermediate results for {len(results)} files\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    # Create final DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save final results\n",
    "    output_file = 'final_audit_results.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSaved final results to {output_file}\")\n",
    "    print(f\"Total records processed: {len(df)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    html_folder = \"html\"  # Replace with your folder path\n",
    "    df = process_html_folder(html_folder)\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nDataFrame Summary:\")\n",
    "    print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204e76ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>block</th>\n",
       "      <th>panchayat</th>\n",
       "      <th>sa_start_date</th>\n",
       "      <th>sa_end_date</th>\n",
       "      <th>gram_sabha_date</th>\n",
       "      <th>public_hearing_date</th>\n",
       "      <th>sa_period_from</th>\n",
       "      <th>sa_period_to</th>\n",
       "      <th>...</th>\n",
       "      <th>photography_expense</th>\n",
       "      <th>shamiana_expense</th>\n",
       "      <th>total_expense</th>\n",
       "      <th>job_cards_with_people</th>\n",
       "      <th>job_cards_updated</th>\n",
       "      <th>job_cards_renewed</th>\n",
       "      <th>demand_registration_process</th>\n",
       "      <th>unmet_demand</th>\n",
       "      <th>payment_agency_problems</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>ALLURI SITHARAMA RAJU</td>\n",
       "      <td>Araku Valley</td>\n",
       "      <td>Chompi</td>\n",
       "      <td>15/12/2022</td>\n",
       "      <td>17/12/2022</td>\n",
       "      <td>17/12/2022</td>\n",
       "      <td>19/12/2022</td>\n",
       "      <td>01/04/2021</td>\n",
       "      <td>31/03/2022</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4955.81</td>\n",
       "      <td>Greater than 75%</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, Some Demand</td>\n",
       "      <td>No</td>\n",
       "      <td>02_0214_0203005_0203005002_2021-2022_12_17_202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>ALLURI SITHARAMA RAJU</td>\n",
       "      <td>Chintapalle</td>\n",
       "      <td>KUDUMUSARI</td>\n",
       "      <td>12/10/2023</td>\n",
       "      <td>15/10/2023</td>\n",
       "      <td>15/10/2023</td>\n",
       "      <td>21/10/2023</td>\n",
       "      <td>01/04/2022</td>\n",
       "      <td>31/03/2023</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7733</td>\n",
       "      <td>Greater than 75%</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mostly</td>\n",
       "      <td>Yes, Some Demand</td>\n",
       "      <td>No</td>\n",
       "      <td>02_0214_0203012_0203012003_2022-2023_10_15_202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>ALLURI SITHARAMA RAJU</td>\n",
       "      <td>Chintapalle</td>\n",
       "      <td>Lothugedda</td>\n",
       "      <td>13/03/2021</td>\n",
       "      <td>18/03/2021</td>\n",
       "      <td>19/03/2021</td>\n",
       "      <td>07/12/2020</td>\n",
       "      <td>01/04/2019</td>\n",
       "      <td>31/03/2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>294.11</td>\n",
       "      <td>3698.73</td>\n",
       "      <td>Greater than 75%</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Some</td>\n",
       "      <td>No, people get work when they want it</td>\n",
       "      <td>No</td>\n",
       "      <td>02_0214_0203012_0203012007_2019-2020_3_19_2021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>ALLURI SITHARAMA RAJU</td>\n",
       "      <td>Araku Valley</td>\n",
       "      <td>Madagada</td>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>09/01/2021</td>\n",
       "      <td>09/01/2021</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>01/04/2019</td>\n",
       "      <td>31/03/2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4052.96</td>\n",
       "      <td>Greater than 75%</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No, people get work when they want it</td>\n",
       "      <td>No</td>\n",
       "      <td>02_0214_0203005_0203005009_2019-2020_1_9_2021_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>ALLURI SITHARAMA RAJU</td>\n",
       "      <td>Addateegala</td>\n",
       "      <td>THIMMAPURAM</td>\n",
       "      <td>29/08/2018</td>\n",
       "      <td>01/09/2018</td>\n",
       "      <td>02/09/2018</td>\n",
       "      <td>04/09/2018</td>\n",
       "      <td>01/04/2017</td>\n",
       "      <td>31/03/2018</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6582</td>\n",
       "      <td>Greater than 75%</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, Some Demand</td>\n",
       "      <td>Yes, Some Problems</td>\n",
       "      <td>02_0214_0204003_0204003019_2017-2018_9_2_2018_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            state               district         block    panchayat  \\\n",
       "0  ANDHRA PRADESH  ALLURI SITHARAMA RAJU  Araku Valley       Chompi   \n",
       "1  ANDHRA PRADESH  ALLURI SITHARAMA RAJU   Chintapalle   KUDUMUSARI   \n",
       "2  ANDHRA PRADESH  ALLURI SITHARAMA RAJU   Chintapalle   Lothugedda   \n",
       "3  ANDHRA PRADESH  ALLURI SITHARAMA RAJU  Araku Valley     Madagada   \n",
       "4  ANDHRA PRADESH  ALLURI SITHARAMA RAJU   Addateegala  THIMMAPURAM   \n",
       "\n",
       "  sa_start_date sa_end_date gram_sabha_date public_hearing_date  \\\n",
       "0    15/12/2022  17/12/2022      17/12/2022          19/12/2022   \n",
       "1    12/10/2023  15/10/2023      15/10/2023          21/10/2023   \n",
       "2    13/03/2021  18/03/2021      19/03/2021          07/12/2020   \n",
       "3    31/12/2020  09/01/2021      09/01/2021          11/01/2021   \n",
       "4    29/08/2018  01/09/2018      02/09/2018          04/09/2018   \n",
       "\n",
       "  sa_period_from sa_period_to  ... photography_expense shamiana_expense  \\\n",
       "0     01/04/2021   31/03/2022  ...                   0                0   \n",
       "1     01/04/2022   31/03/2023  ...                   0                0   \n",
       "2     01/04/2019   31/03/2020  ...                   0           294.11   \n",
       "3     01/04/2019   31/03/2020  ...                   0                0   \n",
       "4     01/04/2017   31/03/2018  ...                   0                0   \n",
       "\n",
       "  total_expense job_cards_with_people job_cards_updated job_cards_renewed  \\\n",
       "0       4955.81      Greater than 75%               Yes               Yes   \n",
       "1          7733      Greater than 75%                No               Yes   \n",
       "2       3698.73      Greater than 75%               Yes               Yes   \n",
       "3       4052.96      Greater than 75%               Yes               Yes   \n",
       "4          6582      Greater than 75%               Yes               Yes   \n",
       "\n",
       "  demand_registration_process                           unmet_demand  \\\n",
       "0                         Yes                       Yes, Some Demand   \n",
       "1                      Mostly                       Yes, Some Demand   \n",
       "2                        Some  No, people get work when they want it   \n",
       "3                          No  No, people get work when they want it   \n",
       "4                         Yes                       Yes, Some Demand   \n",
       "\n",
       "  payment_agency_problems                                        source_file  \n",
       "0                      No  02_0214_0203005_0203005002_2021-2022_12_17_202...  \n",
       "1                      No  02_0214_0203012_0203012003_2022-2023_10_15_202...  \n",
       "2                      No  02_0214_0203012_0203012007_2019-2020_3_19_2021...  \n",
       "3                      No  02_0214_0203005_0203005009_2019-2020_1_9_2021_...  \n",
       "4      Yes, Some Problems  02_0214_0204003_0204003019_2017-2018_9_2_2018_...  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba7a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
